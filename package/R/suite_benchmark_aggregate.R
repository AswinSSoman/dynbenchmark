#' @importFrom sigmoid sigmoid
.benchmark_aggregate_normalisation <- list(
  scalesigmoid = function (xnona, xnazero, multiplier = 1) {
    y <- (xnazero - mean(xnona)) / var(xnona) * multiplier

    sigmoid::sigmoid(y)
  },
  scaletanh = function (xnona, xnazero, multiplier = 1) {
    y <- (xnazero - mean(xnona)) / var(xnona) * multiplier

    tanh(y)
  },
  minmax = function (xnona, xnazero) {
    (xnazero - min(xnona)) / (max(xnona) - min(xnona))
  },
  percentrank = function(xnona, xnazero) {
    percent_rank(xnazero)
  },
  none = "none"
)

#' Normalisation and aggregation function
#'
#' @param data Data as generated by the `07-benchmark/2-retrieve_results.R`` script
#' @param metrics Metrics to normalise
#' @param norm_fun Which normalisation to use
#' @param mean_fun Which mean function to use
#' @param mean_weights Which metrics to use for the calculation of the mean, and which weights
#' @param dataset_source_weights The weights of the dataset sources
#'
#' @export
benchmark_aggregate <- function(
  data,
  metrics,
  norm_fun = names(.benchmark_aggregate_normalisation),
  mean_fun = c("geometric", "harmonic", "arithmetic"),
  mean_weights = set_names(rep(1, length(metrics)), metrics),
  dataset_source_weights = c("real" = 5, "synthetic/dyngen" = 5, "synthetic/dyntoy" = 1, "synthetic/prosstt" = 1, "synthetic/splatter" = 1)
) {

  # add a few columns
  data <- data %>% mutate(
    time = ifelse(error_status != "no_error", 6 * 3600, time_method),
    mem = ifelse(error_status != "no_error", 32 * 10e9, max_mem),
    ltime = log10(time),
    lmem = log10(mem),
    pct_errored = (error_status != "no_error") + 0,
    pct_time_limit = (error_status == "time_limit") + 0,
    pct_memory_limit = (error_status == "memory_limit") + 0,
    pct_execution_error = (error_status == "execution_error") + 0,
    pct_method_error = (error_status == "method_error") + 0
  ) %>%
    mutate_at(metrics, function(x) ifelse(is.na(x), 0, x) %>% pmax(0) %>% pmin(1)) %>%
    group_by(dataset_id) %>%
    mutate(
      rank_time = percent_rank(-ltime),
      rank_mem = percent_rank(-lmem)
    ) %>%
    ungroup()


  # check normalise parameter
  if (is.character(norm_fun)) {
    norm_fun <- .benchmark_aggregate_normalisation[[match.arg(norm_fun)]]
  }

  if (!identical(norm_fun, "none")) {
    preproc_fun <- function(x) {
      x[x < 0] <- 0
      x[x > 1] <- 1

      xnona <- x[!is.na(x)]
      xnazero <- ifelse(is.na(x), 0, x)

      if (length(xnazero) == 1 || all(xnazero == 0)) {
        lst(ret = x)
      } else {
        norm_fun(xnona, xnazero)
      }
    }

    data <-
      data %>%
      group_by(dataset_id) %>%
      mutate_at(set_names(metrics, paste0("norm_", metrics)), preproc_fun) %>%
      ungroup()
    names(mean_weights) <- paste0("norm_", names(mean_weights))
  }

  # check mean parameter
  if (is.character(mean_fun)) {
    mean_fun <- switch(
      match.arg(mean_fun),
      geometric = dyneval::calculate_geometric_mean,
      harmonic = dyneval::calculate_harmonic_mean,
      arithmetic = dyneval::calculate_arithmetic_mean
    )
  }

  calc_mean <- function(df) {
    lis <- df %>% select(!!names(mean_weights)) %>% as.list()
    lis$weights <- mean_weights
    df$overall <- do.call(mean_fun, lis)
    df
  }

  # calculate mean between metrics
  data <- data %>%
    calc_mean()

  # aggregate over replicates
  data_repl <- data %>%
    group_by(method_id, method_name, dataset_id, param_id, dataset_trajectory_type, dataset_source) %>%
    select(-repeat_ix) %>%
    summarise_if(is.numeric, mean) %>%
    ungroup() %>%
    mutate(
      pct_method_error_all = (pct_method_error == 1) + 0,
      pct_method_error_stoch = pct_method_error - pct_method_error_all
    ) %>%
    calc_mean()

  # process trajtype grouped evaluation
  data_trajtype <- data_repl %>%
    group_by(method_id, method_name, param_id, dataset_trajectory_type, dataset_source) %>%
    mutate(n = n()) %>%
    summarise_if(is.numeric, mean) %>%
    ungroup() %>%
    calc_mean()

  # process overall evaluation
  data_method <- data_trajtype %>%
    group_by(method_id, method_name, param_id, dataset_source) %>%
    mutate(n = n()) %>%
    summarise_if(is.numeric, mean) %>%
    ungroup() %>%
    calc_mean() %>%
    mutate(
      dataset_trajectory_type = factor("overall", levels = levels(data$dataset_trajectory_type))
    )

  data_aggregations <-
    bind_rows(data_trajtype, data_method) %>% {
      df <- .
      bind_rows(
        df,
        df %>%
          gather(metric, value, -method_id:-dataset_source) %>%
          group_by(method_id, method_name, param_id, dataset_trajectory_type, metric) %>%
          mutate(dataset_weight = dataset_source_weights[dataset_source]) %>%
          summarise(value = sum(value * dataset_weight) / sum(dataset_weight)) %>%
          ungroup() %>%
          spread(metric, value) %>%
          mutate(dataset_source = "mean")
      )
    }

  lst(
    data,
    data_aggregations
  )
}
formals(benchmark_aggregate)$norm_fun <- names(.benchmark_aggregate_normalisation)
