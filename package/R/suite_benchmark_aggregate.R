#' @importFrom sigmoid sigmoid
.benchmark_aggregate_normalisation <- list(
  scalesigmoid = function (xnona, xnazero = xnona, multiplier = 1) {
    y <- (xnazero - mean(xnona)) / sd(xnona) * multiplier

    sigmoid::sigmoid(y)
  },
  scaletanh = function (xnona, xnazero = xnona, multiplier = 1) {
    y <- (xnazero - mean(xnona)) / sd(xnona) * multiplier

    tanh(y)
  },
  minmax = function (xnona, xnazero = xnona) {
    (xnazero - min(xnona)) / (max(xnona) - min(xnona))
  },
  percentrank = function(xnona, xnazero = xnona) {
    percent_rank(xnazero)
  },
  normal = function(xnona, xnazero = xnona) {
    y <- (xnazero - mean(xnona)) / sd(xnona)
    pnorm(y)
  },
  none = "none"
)

#' Normalisation and aggregation function
#'
#' @param data Data as generated by the `06-benchmark/2-retrieve_results.R`` script
#' @param metrics Metrics to normalise
#' @param norm_fun Which normalisation to use
#' @param mean_fun Which mean function to use
#' @param mean_weights Which metrics to use for the calculation of the mean, and which weights
#' @param dataset_source_weights The weights of the dataset sources
#'
#' @export
benchmark_aggregate <- function(
  data,
  metrics = c("correlation", "him", "featureimp_cor", "F1_branches"),
  norm_fun = "normal",
  mean_fun = "geometric",
  mean_weights = set_names(rep(1, length(metrics)), metrics),
  dataset_source_weights = get_default_dataset_weights()
) {

  # add a few columns
  data <- data %>% mutate(
    pct_errored = (error_status != "no_error") + 0,
    pct_time_limit = (error_status == "time_limit") + 0,
    pct_memory_limit = (error_status == "memory_limit") + 0,
    pct_execution_error = (error_status == "execution_error") + 0,
    pct_method_error = (error_status == "method_error") + 0
  )

  # clip values
  data <- data %>% mutate_at(metrics, function(x) ifelse(is.na(x), 0, x) %>% pmax(0) %>% pmin(1))


  # check normalise parameter
  if (is.character(norm_fun)) {
    norm_fun <- .benchmark_aggregate_normalisation[[match.arg(norm_fun, choices = names(.benchmark_aggregate_normalisation))]]
  }

  if (!identical(norm_fun, "none")) {
    preproc_fun <- function(x) {
      x[x < 0] <- 0
      x[x > 1] <- 1

      xnona <- x[!is.na(x)]
      xnazero <- ifelse(is.na(x), 0, x)

      if (length(xnazero) == 1 || all(xnazero == 0)) {
        x
      } else {
        norm_fun(xnona, xnazero)
      }
    }

    data <-
      data %>%
      group_by(dataset_id) %>%
      mutate_at(set_names(metrics, paste0("norm_", metrics)), preproc_fun) %>%
      ungroup()
    names(mean_weights) <- paste0("norm_", names(mean_weights))
  }

  # check mean parameter
  if (is.character(mean_fun)) {
    mean_fun <- switch(
      match.arg(mean_fun),
      geometric = dyneval::calculate_geometric_mean,
      harmonic = dyneval::calculate_harmonic_mean,
      arithmetic = dyneval::calculate_arithmetic_mean
    )
  }

  calc_mean <- function(df) {
    lis <- df %>% select(!!names(mean_weights)) %>% as.list()
    lis$weights <- mean_weights
    df$overall <- do.call(mean_fun, lis)
    df
  }

  # calculate mean between metrics
  data <- data %>%
    calc_mean()

  # aggregate over replicates
  data_repl <- data %>%
    group_by(method_id, method_name, dataset_id, param_id, dataset_trajectory_type, dataset_source) %>%
    select(-repeat_ix) %>%
    summarise_if(is.numeric, mean) %>%
    ungroup() %>%
    mutate(
      pct_method_error_all = (pct_method_error == 1) + 0,
      pct_method_error_stoch = pct_method_error - pct_method_error_all
    ) %>%
    calc_mean()

  # process source grouped evaluation
  data_source <- data_repl %>%
    group_by(method_id, method_name, param_id, dataset_trajectory_type, dataset_source) %>%
    summarise_if(is.numeric, mean) %>%
    ungroup() %>%
    calc_mean()

  # process overall evaluation
  data_method <- data_source %>%
    gather(metric, value, -method_id:-dataset_source) %>%
    group_by(method_id, method_name, param_id, dataset_trajectory_type, metric) %>%
    mutate(dataset_weight = dataset_source_weights[dataset_source]) %>%
    summarise(value = sum(value * dataset_weight) / sum(dataset_weight)) %>%
    spread(metric, value) %>%
    ungroup() %>%
    calc_mean() %>%
    mutate(
      dataset_source = "mean"
    )

  data_aggregations <-
    bind_rows(data_source, data_method) %>% {
      df <- .
      bind_rows(
        df,
        df %>%
          group_by(method_id, method_name, param_id, dataset_source) %>%
          summarise_if(is.numeric, mean) %>%
          ungroup() %>%
          calc_mean() %>%
          mutate(dataset_trajectory_type = factor("overall", levels = levels(data$dataset_trajectory_type)))
      )
    }

  lst(
    data,
    data_aggregations
  )
}


get_default_dataset_weights <- function() {
  if (tryCatch(is.character(get_dynbenchmark_folder()), error = function(e) FALSE) && file.exists(result_file("dataset_source_weights.rds", "07-benchmark"))) {
    read_rds(result_file("dataset_source_weights.rds", "07-benchmark"))
  } else {
    c("real" = 5, "synthetic/dyngen" = 5, "synthetic/dyntoy" = 1, "synthetic/prosstt" = 1, "synthetic/splatter" = 1)
  }
}
